c:\Users\Thomas\conda\envs\audio\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
c:\Users\Thomas\conda\envs\audio\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=4, bias=True)
)
Initializing Datasets and Dataloaders...
Params to learn:
	 conv1.weight
	 bn1.weight
	 bn1.bias
	 layer1.0.conv1.weight
	 layer1.0.bn1.weight
	 layer1.0.bn1.bias
	 layer1.0.conv2.weight
	 layer1.0.bn2.weight
	 layer1.0.bn2.bias
	 layer1.1.conv1.weight
	 layer1.1.bn1.weight
	 layer1.1.bn1.bias
	 layer1.1.conv2.weight
	 layer1.1.bn2.weight
	 layer1.1.bn2.bias
	 layer2.0.conv1.weight
	 layer2.0.bn1.weight
	 layer2.0.bn1.bias
	 layer2.0.conv2.weight
	 layer2.0.bn2.weight
	 layer2.0.bn2.bias
	 layer2.0.downsample.0.weight
	 layer2.0.downsample.1.weight
	 layer2.0.downsample.1.bias
	 layer2.1.conv1.weight
	 layer2.1.bn1.weight
	 layer2.1.bn1.bias
	 layer2.1.conv2.weight
	 layer2.1.bn2.weight
	 layer2.1.bn2.bias
	 layer3.0.conv1.weight
	 layer3.0.bn1.weight
	 layer3.0.bn1.bias
	 layer3.0.conv2.weight
	 layer3.0.bn2.weight
	 layer3.0.bn2.bias
	 layer3.0.downsample.0.weight
	 layer3.0.downsample.1.weight
	 layer3.0.downsample.1.bias
	 layer3.1.conv1.weight
	 layer3.1.bn1.weight
	 layer3.1.bn1.bias
	 layer3.1.conv2.weight
	 layer3.1.bn2.weight
	 layer3.1.bn2.bias
	 layer4.0.conv1.weight
	 layer4.0.bn1.weight
	 layer4.0.bn1.bias
	 layer4.0.conv2.weight
	 layer4.0.bn2.weight
	 layer4.0.bn2.bias
	 layer4.0.downsample.0.weight
	 layer4.0.downsample.1.weight
	 layer4.0.downsample.1.bias
	 layer4.1.conv1.weight
	 layer4.1.bn1.weight
	 layer4.1.bn1.bias
	 layer4.1.conv2.weight
	 layer4.1.bn2.weight
	 layer4.1.bn2.bias
	 fc.weight
	 fc.bias
Epoch 0/199
----------
train Loss: 1.2154 Acc: 0.4634
val Loss: 2.0778 Acc: 0.1230
Epoch 1/199
----------
train Loss: 1.0460 Acc: 0.5652
val Loss: 1.8278 Acc: 0.5167
Epoch 2/199
----------
train Loss: 0.9784 Acc: 0.5933
val Loss: 2.0629 Acc: 0.6144
Epoch 3/199
----------
train Loss: 0.9166 Acc: 0.6228
val Loss: 1.6845 Acc: 0.6259
Epoch 4/199
----------
train Loss: 0.8652 Acc: 0.6619
val Loss: 2.2849 Acc: 0.3648
Epoch 5/199
----------
train Loss: 0.8629 Acc: 0.6485
val Loss: 2.3881 Acc: 0.5819
Epoch 6/199
----------
train Loss: 0.7974 Acc: 0.6633
val Loss: 2.4620 Acc: 0.4979
Epoch 7/199
----------
train Loss: 0.7883 Acc: 0.6845
val Loss: 1.5216 Acc: 0.6460
Epoch 8/199
----------
train Loss: 0.7522 Acc: 0.7001
val Loss: 2.0558 Acc: 0.4361
Epoch 9/199
----------
train Loss: 0.7200 Acc: 0.7158
val Loss: 1.5267 Acc: 0.6180
Epoch 10/199
----------
train Loss: 0.7190 Acc: 0.7172
val Loss: 2.3997 Acc: 0.6048
Epoch 11/199
----------
train Loss: 0.7028 Acc: 0.7227
val Loss: 2.0836 Acc: 0.6690
Epoch 12/199
----------
train Loss: 0.7088 Acc: 0.7149
val Loss: 2.2587 Acc: 0.5349
Epoch 13/199
----------
train Loss: 0.6793 Acc: 0.7379
val Loss: 1.6693 Acc: 0.5976
Epoch 14/199
----------
train Loss: 0.6784 Acc: 0.7287
val Loss: 2.0488 Acc: 0.6071
Epoch 15/199
----------
train Loss: 0.6210 Acc: 0.7421
val Loss: 1.8169 Acc: 0.6328
Epoch 16/199
----------
train Loss: 0.6299 Acc: 0.7563
val Loss: 2.3681 Acc: 0.4813
Epoch 17/199
----------
train Loss: 0.5644 Acc: 0.7863
val Loss: 1.8698 Acc: 0.5632
Epoch 18/199
----------
train Loss: 0.5986 Acc: 0.7752
val Loss: 1.7668 Acc: 0.6562
Epoch 19/199
----------
train Loss: 0.5873 Acc: 0.7642
val Loss: 1.8898 Acc: 0.6292
Epoch 20/199
----------
train Loss: 0.5823 Acc: 0.7651
val Loss: 2.1339 Acc: 0.5750
Epoch 21/199
----------
train Loss: 0.5518 Acc: 0.7729
val Loss: 1.8631 Acc: 0.6578
Epoch 22/199
----------
train Loss: 0.5468 Acc: 0.7817
val Loss: 2.2913 Acc: 0.6166
Epoch 23/199
----------
train Loss: 0.5485 Acc: 0.7789
val Loss: 2.0540 Acc: 0.6526
Epoch 24/199
----------
train Loss: 0.5219 Acc: 0.7996
val Loss: 1.8263 Acc: 0.6680
Epoch 25/199
----------
train Loss: 0.5184 Acc: 0.7978
val Loss: 1.7723 Acc: 0.6333
Epoch 26/199
----------
train Loss: 0.4925 Acc: 0.7982
val Loss: 1.9871 Acc: 0.5560
Epoch 27/199
----------
train Loss: 0.5104 Acc: 0.8042
val Loss: 2.2709 Acc: 0.5689
Epoch 28/199
----------
train Loss: 0.4849 Acc: 0.8111
val Loss: 2.1060 Acc: 0.6583
Epoch 29/199
----------
train Loss: 0.5177 Acc: 0.8029
val Loss: 2.5679 Acc: 0.6636
Epoch 30/199
----------
train Loss: 0.4920 Acc: 0.8139
val Loss: 2.0269 Acc: 0.6410
Epoch 31/199
----------
train Loss: 0.4715 Acc: 0.8231
val Loss: 1.5446 Acc: 0.6410
Epoch 32/199
----------
train Loss: 0.4622 Acc: 0.8135
val Loss: 1.3912 Acc: 0.6701
Epoch 33/199
----------
train Loss: 0.4661 Acc: 0.8176
val Loss: 1.3704 Acc: 0.6729
Epoch 34/199
----------
train Loss: 0.4233 Acc: 0.8365
val Loss: 1.8165 Acc: 0.6501
Epoch 35/199
----------
train Loss: 0.4230 Acc: 0.8314
val Loss: 1.3721 Acc: 0.6673
Epoch 36/199
----------
train Loss: 0.4453 Acc: 0.8268
val Loss: 1.6014 Acc: 0.6575
Epoch 37/199
----------
train Loss: 0.4064 Acc: 0.8448
val Loss: 2.1083 Acc: 0.5768
Epoch 38/199
----------
train Loss: 0.4373 Acc: 0.8287
val Loss: 2.0394 Acc: 0.6243
Epoch 39/199
----------
train Loss: 0.4076 Acc: 0.8406
val Loss: 1.3046 Acc: 0.6536
Epoch 40/199
----------
train Loss: 0.4039 Acc: 0.8475
val Loss: 1.6647 Acc: 0.6586
Epoch 41/199
----------
train Loss: 0.3822 Acc: 0.8540
val Loss: 1.4542 Acc: 0.6251
Epoch 42/199
----------
train Loss: 0.4082 Acc: 0.8485
val Loss: 0.8695 Acc: 0.7140
Epoch 43/199
----------
train Loss: 0.3910 Acc: 0.8466
val Loss: 1.8415 Acc: 0.6190
Epoch 44/199
----------
train Loss: 0.3648 Acc: 0.8586
val Loss: 1.5750 Acc: 0.6557
Epoch 45/199
----------
train Loss: 0.4092 Acc: 0.8374
val Loss: 1.2877 Acc: 0.6395
Epoch 46/199
----------
train Loss: 0.3526 Acc: 0.8710
val Loss: 1.4860 Acc: 0.6654
Epoch 47/199
----------
train Loss: 0.3822 Acc: 0.8471
val Loss: 1.9845 Acc: 0.6383
Epoch 48/199
----------
train Loss: 0.3878 Acc: 0.8540
val Loss: 1.6491 Acc: 0.5977
Epoch 49/199
----------
train Loss: 0.3302 Acc: 0.8692
val Loss: 1.3304 Acc: 0.6331
Epoch 50/199
----------
train Loss: 0.3167 Acc: 0.8862
val Loss: 0.8837 Acc: 0.7161
Epoch 51/199
----------
train Loss: 0.3639 Acc: 0.8554
val Loss: 1.1998 Acc: 0.6536
Epoch 52/199
----------
train Loss: 0.3627 Acc: 0.8623
val Loss: 1.5881 Acc: 0.6005
Epoch 53/199
----------
train Loss: 0.3036 Acc: 0.8885
val Loss: 1.8837 Acc: 0.6120
Epoch 54/199
----------
train Loss: 0.3471 Acc: 0.8595
val Loss: 1.5596 Acc: 0.5724
Epoch 55/199
----------
train Loss: 0.3389 Acc: 0.8692
val Loss: 2.0478 Acc: 0.6063
Epoch 56/199
----------
train Loss: 0.3044 Acc: 0.8770
val Loss: 1.4796 Acc: 0.6190
Epoch 57/199
----------
train Loss: 0.3306 Acc: 0.8715
val Loss: 2.0206 Acc: 0.6013
Epoch 58/199
----------
train Loss: 0.3263 Acc: 0.8747
val Loss: 3.3410 Acc: 0.5645
Epoch 59/199
----------
train Loss: 0.3327 Acc: 0.8696
val Loss: 1.6735 Acc: 0.6398
Epoch 60/199
----------
train Loss: 0.3470 Acc: 0.8687
val Loss: 0.8499 Acc: 0.7570
Epoch 61/199
----------
train Loss: 0.3062 Acc: 0.8779
val Loss: 1.2963 Acc: 0.6501
Epoch 62/199
----------
train Loss: 0.3382 Acc: 0.8779
val Loss: 1.6125 Acc: 0.6349
Epoch 63/199
----------
train Loss: 0.3177 Acc: 0.8715
val Loss: 2.9164 Acc: 0.6053
Epoch 64/199
----------
train Loss: 0.2973 Acc: 0.8798
val Loss: 2.6707 Acc: 0.6157
Epoch 65/199
----------
train Loss: 0.3167 Acc: 0.8775
val Loss: 1.9797 Acc: 0.6099
Epoch 66/199
----------
train Loss: 0.3069 Acc: 0.8770
val Loss: 3.5060 Acc: 0.6095
Epoch 67/199
----------
train Loss: 0.3237 Acc: 0.8789
val Loss: 2.1287 Acc: 0.6009
Epoch 68/199
----------
train Loss: 0.3028 Acc: 0.8881
val Loss: 1.2046 Acc: 0.6770
Epoch 69/199
----------
train Loss: 0.2868 Acc: 0.8950
val Loss: 0.9440 Acc: 0.7153
Epoch 70/199
----------
train Loss: 0.3149 Acc: 0.8848
val Loss: 1.9504 Acc: 0.6446
Epoch 71/199
----------
train Loss: 0.3127 Acc: 0.8802
val Loss: 1.8825 Acc: 0.6310
Epoch 72/199
----------
train Loss: 0.2877 Acc: 0.8908
val Loss: 1.8956 Acc: 0.5855
Epoch 73/199
----------
train Loss: 0.2728 Acc: 0.8890
val Loss: 2.1333 Acc: 0.5573
Epoch 74/199
----------
train Loss: 0.3012 Acc: 0.8848
val Loss: 1.7781 Acc: 0.6269
Epoch 75/199
----------
train Loss: 0.2628 Acc: 0.8936
val Loss: 1.8341 Acc: 0.6100
Epoch 76/199
----------
train Loss: 0.3172 Acc: 0.8747
val Loss: 3.0814 Acc: 0.6287
Epoch 77/199
----------
train Loss: 0.2632 Acc: 0.8968
val Loss: 2.2500 Acc: 0.6146
Epoch 78/199
----------
train Loss: 0.2795 Acc: 0.8922
val Loss: 2.3537 Acc: 0.6013
Epoch 79/199
----------
train Loss: 0.2539 Acc: 0.9028
val Loss: 3.1091 Acc: 0.5876
Epoch 80/199
----------
train Loss: 0.2691 Acc: 0.8895
val Loss: 2.2488 Acc: 0.5925
Epoch 81/199
----------
train Loss: 0.2718 Acc: 0.8927
val Loss: 3.1706 Acc: 0.6192
Epoch 82/199
----------
train Loss: 0.2574 Acc: 0.8927
val Loss: 3.1040 Acc: 0.5896
Epoch 83/199
----------
train Loss: 0.2758 Acc: 0.8996
val Loss: 3.3908 Acc: 0.5370
Epoch 84/199
----------
train Loss: 0.2562 Acc: 0.9047
val Loss: 2.6415 Acc: 0.5580
Epoch 85/199
----------
train Loss: 0.2810 Acc: 0.8895
val Loss: 4.1603 Acc: 0.6336
Epoch 86/199
----------
train Loss: 0.2476 Acc: 0.9051
val Loss: 3.2854 Acc: 0.5894
Epoch 87/199
----------
train Loss: 0.2713 Acc: 0.9014
val Loss: 2.4010 Acc: 0.5845
Epoch 88/199
----------
train Loss: 0.2700 Acc: 0.8881
val Loss: 3.5804 Acc: 0.6316
Epoch 89/199
----------
train Loss: 0.2660 Acc: 0.8987
val Loss: 3.0858 Acc: 0.5864
Epoch 90/199
----------
train Loss: 0.2836 Acc: 0.8812
val Loss: 2.1365 Acc: 0.6212
Epoch 91/199
----------
train Loss: 0.2561 Acc: 0.9033
val Loss: 1.9091 Acc: 0.6344
Epoch 92/199
----------
train Loss: 0.2272 Acc: 0.9065
val Loss: 1.9309 Acc: 0.5858
Epoch 93/199
----------
train Loss: 0.2622 Acc: 0.9060
val Loss: 2.7406 Acc: 0.5760
Epoch 94/199
----------
train Loss: 0.2474 Acc: 0.9083
val Loss: 3.3109 Acc: 0.5620
Epoch 95/199
----------
train Loss: 0.2416 Acc: 0.9014
val Loss: 1.6679 Acc: 0.5827
Epoch 96/199
----------
train Loss: 0.2330 Acc: 0.9120
val Loss: 1.1670 Acc: 0.7195
Epoch 97/199
----------
train Loss: 0.2532 Acc: 0.8987
val Loss: 2.0927 Acc: 0.5779
Epoch 98/199
----------
train Loss: 0.2495 Acc: 0.9019
val Loss: 0.8140 Acc: 0.7674
Epoch 99/199
----------
train Loss: 0.2240 Acc: 0.9106
val Loss: 1.5404 Acc: 0.6303
Epoch 100/199
----------
train Loss: 0.2587 Acc: 0.8927
val Loss: 1.4899 Acc: 0.6598
Epoch 101/199
----------
train Loss: 0.2232 Acc: 0.9143
val Loss: 1.3688 Acc: 0.6722
Epoch 102/199
----------
train Loss: 0.2624 Acc: 0.8954
val Loss: 1.7788 Acc: 0.5707
Epoch 103/199
----------
train Loss: 0.2513 Acc: 0.8996
val Loss: 2.9075 Acc: 0.4637
Epoch 104/199
----------
train Loss: 0.2530 Acc: 0.9014
val Loss: 1.8094 Acc: 0.6036
Epoch 105/199
----------
train Loss: 0.2241 Acc: 0.9111
val Loss: 1.9632 Acc: 0.5907
Epoch 106/199
----------
train Loss: 0.2581 Acc: 0.8996
val Loss: 2.1759 Acc: 0.5416
Epoch 107/199
----------
train Loss: 0.2358 Acc: 0.9125
val Loss: 1.0998 Acc: 0.7079
Epoch 108/199
----------
train Loss: 0.2237 Acc: 0.9106
val Loss: 1.7325 Acc: 0.6313
Epoch 109/199
----------
train Loss: 0.2143 Acc: 0.9171
val Loss: 1.3985 Acc: 0.6514
Epoch 110/199
----------
train Loss: 0.2021 Acc: 0.9129
val Loss: 1.6863 Acc: 0.6212
Epoch 111/199
----------
train Loss: 0.2095 Acc: 0.9157
val Loss: 1.7010 Acc: 0.5963
Epoch 112/199
----------
train Loss: 0.2616 Acc: 0.8936
val Loss: 3.2078 Acc: 0.5812
Epoch 113/199
----------
train Loss: 0.2144 Acc: 0.9139
val Loss: 3.3430 Acc: 0.6171
Epoch 114/199
----------
train Loss: 0.2228 Acc: 0.9134
val Loss: 3.7467 Acc: 0.6544
Epoch 115/199
----------
train Loss: 0.2224 Acc: 0.9166
val Loss: 2.9799 Acc: 0.6200
Epoch 116/199
----------
train Loss: 0.2293 Acc: 0.9074
val Loss: 3.2676 Acc: 0.5494
Epoch 117/199
----------
train Loss: 0.2145 Acc: 0.9152
val Loss: 2.7582 Acc: 0.5840
Epoch 118/199
----------
train Loss: 0.2270 Acc: 0.9074
val Loss: 1.2909 Acc: 0.6676
Epoch 119/199
----------
train Loss: 0.2146 Acc: 0.9139
val Loss: 1.6986 Acc: 0.6550
Epoch 120/199
----------
train Loss: 0.2003 Acc: 0.9180
val Loss: 1.5293 Acc: 0.6369
Epoch 121/199
----------
train Loss: 0.2064 Acc: 0.9148
val Loss: 1.8598 Acc: 0.6405
Epoch 122/199
----------
train Loss: 0.2159 Acc: 0.9143
val Loss: 1.5287 Acc: 0.6455
Epoch 123/199
----------
train Loss: 0.2030 Acc: 0.9143
val Loss: 2.8426 Acc: 0.5404
Epoch 124/199
----------
train Loss: 0.2046 Acc: 0.9199
val Loss: 1.6602 Acc: 0.6622
Epoch 125/199
----------
train Loss: 0.2120 Acc: 0.9143
val Loss: 1.7457 Acc: 0.5971
Epoch 126/199
----------
train Loss: 0.1969 Acc: 0.9258
val Loss: 1.7099 Acc: 0.6398
Epoch 127/199
----------
train Loss: 0.1902 Acc: 0.9222
val Loss: 2.5269 Acc: 0.6161
Epoch 128/199
----------
train Loss: 0.2164 Acc: 0.9217
val Loss: 2.1233 Acc: 0.5828
Epoch 129/199
----------
train Loss: 0.2070 Acc: 0.9125
val Loss: 2.0664 Acc: 0.6362
Epoch 130/199
----------
train Loss: 0.2148 Acc: 0.9134
val Loss: 1.4253 Acc: 0.6523
Epoch 131/199
----------
train Loss: 0.2047 Acc: 0.9208
val Loss: 2.9137 Acc: 0.5881
Epoch 132/199
----------
train Loss: 0.2048 Acc: 0.9226
val Loss: 1.4846 Acc: 0.6190
Epoch 133/199
----------
train Loss: 0.2076 Acc: 0.9171
val Loss: 1.3620 Acc: 0.6554
Epoch 134/199
----------
train Loss: 0.2252 Acc: 0.9116
val Loss: 1.2855 Acc: 0.6632
Epoch 135/199
----------
train Loss: 0.2046 Acc: 0.9185
val Loss: 2.8775 Acc: 0.5467
Epoch 136/199
----------
train Loss: 0.2090 Acc: 0.9152
val Loss: 3.1943 Acc: 0.5576
Epoch 137/199
----------
train Loss: 0.2061 Acc: 0.9148
val Loss: 1.5624 Acc: 0.6737
Epoch 138/199
----------
train Loss: 0.1994 Acc: 0.9212
val Loss: 2.6256 Acc: 0.6243
Epoch 139/199
----------
train Loss: 0.1991 Acc: 0.9162
val Loss: 1.7477 Acc: 0.6184
Epoch 140/199
----------
train Loss: 0.1910 Acc: 0.9291
val Loss: 2.6032 Acc: 0.6243
Epoch 141/199
----------
train Loss: 0.2064 Acc: 0.9203
val Loss: 3.0168 Acc: 0.5629
Epoch 142/199
----------
train Loss: 0.2070 Acc: 0.9152
val Loss: 3.0427 Acc: 0.5871
Epoch 143/199
----------
train Loss: 0.2106 Acc: 0.9185
val Loss: 2.3646 Acc: 0.5884
Epoch 144/199
----------
train Loss: 0.1952 Acc: 0.9212
val Loss: 2.7734 Acc: 0.5927
Epoch 145/199
----------
train Loss: 0.2139 Acc: 0.9231
val Loss: 2.0386 Acc: 0.6406
Epoch 146/199
----------
train Loss: 0.1899 Acc: 0.9263
val Loss: 3.7343 Acc: 0.5902
Epoch 147/199
----------
train Loss: 0.1893 Acc: 0.9240
val Loss: 2.4775 Acc: 0.6485
Epoch 148/199
----------
train Loss: 0.1847 Acc: 0.9231
val Loss: 3.0102 Acc: 0.6067
Epoch 149/199
----------
train Loss: 0.1810 Acc: 0.9272
val Loss: 4.6925 Acc: 0.5876
Epoch 150/199
----------
train Loss: 0.1893 Acc: 0.9240
val Loss: 3.1319 Acc: 0.6166
Epoch 151/199
----------
train Loss: 0.2103 Acc: 0.9166
val Loss: 3.5796 Acc: 0.5498
Epoch 152/199
----------
train Loss: 0.1844 Acc: 0.9268
val Loss: 3.2204 Acc: 0.5954
Epoch 153/199
----------
train Loss: 0.1789 Acc: 0.9240
val Loss: 2.4849 Acc: 0.6100
Epoch 154/199
----------
train Loss: 0.2262 Acc: 0.9139
val Loss: 3.9901 Acc: 0.6228
Epoch 155/199
----------
train Loss: 0.1804 Acc: 0.9189
val Loss: 3.6574 Acc: 0.5936
Epoch 156/199
----------
train Loss: 0.1948 Acc: 0.9240
val Loss: 1.9774 Acc: 0.5969
Epoch 157/199
----------
train Loss: 0.1937 Acc: 0.9180
val Loss: 1.1964 Acc: 0.7120
Epoch 158/199
----------
train Loss: 0.1924 Acc: 0.9203
val Loss: 3.0516 Acc: 0.5432
Epoch 159/199
----------
train Loss: 0.2032 Acc: 0.9222
val Loss: 3.5390 Acc: 0.5822
Epoch 160/199
----------
train Loss: 0.1830 Acc: 0.9295
val Loss: 2.7551 Acc: 0.5835
Epoch 161/199
----------
train Loss: 0.1893 Acc: 0.9240
val Loss: 2.3795 Acc: 0.6092
Epoch 162/199
----------
train Loss: 0.1982 Acc: 0.9235
val Loss: 3.2952 Acc: 0.6162
Epoch 163/199
----------
train Loss: 0.1826 Acc: 0.9240
val Loss: 2.1281 Acc: 0.5930
Epoch 164/199
----------
train Loss: 0.2086 Acc: 0.9185
val Loss: 3.5191 Acc: 0.5773
Epoch 165/199
----------
train Loss: 0.1779 Acc: 0.9226
val Loss: 2.7143 Acc: 0.6058
Epoch 166/199
----------
train Loss: 0.1828 Acc: 0.9291
val Loss: 2.8251 Acc: 0.5963
Epoch 167/199
----------
train Loss: 0.1858 Acc: 0.9199
val Loss: 4.3312 Acc: 0.6018
Epoch 168/199
----------
train Loss: 0.1842 Acc: 0.9245
val Loss: 4.4831 Acc: 0.5918
Epoch 169/199
----------
train Loss: 0.2028 Acc: 0.9235
val Loss: 2.9502 Acc: 0.6072
Epoch 170/199
----------
train Loss: 0.1787 Acc: 0.9272
val Loss: 1.6056 Acc: 0.6560
Epoch 171/199
----------
train Loss: 0.1859 Acc: 0.9222
val Loss: 1.6064 Acc: 0.6591
Epoch 172/199
----------
train Loss: 0.1756 Acc: 0.9272
val Loss: 1.7971 Acc: 0.6028
Epoch 173/199
----------
train Loss: 0.1716 Acc: 0.9314
val Loss: 1.4703 Acc: 0.6658
Epoch 174/199
----------
train Loss: 0.1972 Acc: 0.9254
val Loss: 1.6431 Acc: 0.6536
Epoch 175/199
----------
train Loss: 0.1800 Acc: 0.9332
val Loss: 2.2846 Acc: 0.6033
Epoch 176/199
----------
train Loss: 0.1782 Acc: 0.9272
val Loss: 1.5129 Acc: 0.6678
Epoch 177/199
----------
train Loss: 0.1709 Acc: 0.9351
val Loss: 1.2257 Acc: 0.6853
Epoch 178/199
----------
train Loss: 0.1907 Acc: 0.9268
val Loss: 1.1335 Acc: 0.7119
Epoch 179/199
----------
train Loss: 0.1753 Acc: 0.9291
val Loss: 1.8296 Acc: 0.5858
Epoch 180/199
----------
train Loss: 0.1766 Acc: 0.9258
val Loss: 0.9267 Acc: 0.7888
Epoch 181/199
----------
train Loss: 0.1972 Acc: 0.9245
val Loss: 1.7673 Acc: 0.6521
Epoch 182/199
----------
train Loss: 0.1658 Acc: 0.9341
val Loss: 0.9969 Acc: 0.7590
Epoch 183/199
----------
train Loss: 0.1706 Acc: 0.9304
val Loss: 1.9526 Acc: 0.6716
Epoch 184/199
----------
train Loss: 0.1725 Acc: 0.9318
val Loss: 1.6212 Acc: 0.6804
Epoch 185/199
----------
train Loss: 0.1802 Acc: 0.9258
val Loss: 1.6087 Acc: 0.6834
Epoch 186/199
----------
train Loss: 0.1827 Acc: 0.9235
val Loss: 1.8803 Acc: 0.6359
Epoch 187/199
----------
train Loss: 0.1546 Acc: 0.9309
val Loss: 4.9905 Acc: 0.5275
Epoch 188/199
----------
train Loss: 0.1743 Acc: 0.9272
val Loss: 2.7302 Acc: 0.5324
Epoch 189/199
----------
train Loss: 0.1746 Acc: 0.9217
val Loss: 1.6701 Acc: 0.6477
Epoch 190/199
----------
train Loss: 0.1857 Acc: 0.9235
val Loss: 2.1683 Acc: 0.6067
Epoch 191/199
----------
train Loss: 0.1609 Acc: 0.9323
val Loss: 3.9876 Acc: 0.5842
Epoch 192/199
----------
train Loss: 0.1670 Acc: 0.9295
val Loss: 3.0370 Acc: 0.5863
Epoch 193/199
----------
train Loss: 0.1830 Acc: 0.9217
val Loss: 4.4679 Acc: 0.6336
Epoch 194/199
----------
train Loss: 0.1763 Acc: 0.9258
val Loss: 2.1471 Acc: 0.6521
Epoch 195/199
----------
train Loss: 0.1913 Acc: 0.9185
val Loss: 1.2927 Acc: 0.7213
Epoch 196/199
----------
train Loss: 0.1818 Acc: 0.9263
val Loss: 1.4403 Acc: 0.7012
Epoch 197/199
----------
train Loss: 0.1602 Acc: 0.9341
val Loss: 1.3726 Acc: 0.7119
Epoch 198/199
----------
train Loss: 0.1756 Acc: 0.9263
val Loss: 1.8453 Acc: 0.6698
Epoch 199/199
----------
train Loss: 0.1630 Acc: 0.9323
val Loss: 1.2375 Acc: 0.6968
Training complete in 40m 27s
Best val Acc: 0.788802
Requirement already satisfied: requests in c:\users\thomas\conda\envs\audio\lib\site-packages (2.28.2)
Requirement already satisfied: certifi>=2017.4.17 in c:\users\thomas\conda\envs\audio\lib\site-packages (from requests) (2022.12.7)
Requirement already satisfied: charset-normalizer<4,>=2 in c:\users\thomas\conda\envs\audio\lib\site-packages (from requests) (3.1.0)
Requirement already satisfied: idna<4,>=2.5 in c:\users\thomas\conda\envs\audio\lib\site-packages (from requests) (3.4)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\users\thomas\conda\envs\audio\lib\site-packages (from requests) (1.26.14)
Note: you may need to restart the kernel to use updated packages.
Requirement already satisfied: sklearn in c:\users\thomas\conda\envs\audio\lib\site-packages (0.0.post1)
Note: you may need to restart the kernel to use updated packages.
PyTorch Version:  1.13.1+cu117
Torchvision Version:  0.14.1+cu117