{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.dominodatalab.com/blog/getting-started-with-k-means-clustering-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "# import some data to play with\n",
    "data = pd.read_csv('kmeans.csv', header='infer')\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data['class'])\n",
    "data['class']=le.transform(data['class'])\n",
    "\n",
    "#data1 = data.drop(columns=['class', \"mfcc_2_mean\", \"mfcc_3_mean\",  \"mfcc_4_mean\", \"mfcc_5_mean\", \"mfcc_6_mean\", \"mfcc_7_mean\", \"mfcc_8_mean\",\"mfcc_9_mean\",\"mfcc_10_mean\",\"mfcc_11_mean\",\"mfcc_12_mean\",\t\"mfcc_13_mean\"])\n",
    "data1 = data.sample(frac=0.05, replace=True, random_state=1)\n",
    "data = data.sample(frac=0.05, replace=True, random_state=1)\n",
    "\n",
    "X = data1\n",
    "y = data['class']\n",
    "#names = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Put data onto the same standard scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(data1)\n",
    "data1=scaler.fit_transform(data1)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data1[1:,0],data1[1:,1:])\n",
    "plt.xlabel('ZCR_MEAN')\n",
    "plt.ylabel('MFCC_1_MEAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=42) \n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix=confusion_matrix(y, kmeans.labels_) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', \n",
    "                ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://notebook.community/ml4a/ml4a-guides/notebooks/audio-tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install librosa==0.7.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import fnmatch\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scan some directory of audio files and collect all their paths into a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1598 .wav files in D:\\PhD-data\\Tarcutta-DryA-test-8-10\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\\\PhD-data\\\\Tarcutta-DryA-test-8-10'\n",
    "\n",
    "files = []\n",
    "for root, dirnames, filenames in os.walk(path):\n",
    "    for filename in fnmatch.filter(filenames, '*.wav'):\n",
    "        files.append(os.path.join(root, filename))\n",
    "\n",
    "print(\"found %d .wav files in %s\"%(len(files),path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Create an empty list to store the extracted features\n",
    "# features = []\n",
    "\n",
    "# # Loop through all file paths\n",
    "# for file_path in files:\n",
    "#     # Load the audio file\n",
    "#     y, sr = librosa.load(file_path)\n",
    "    \n",
    "#     # Extract the MFCC features and their first and second order derivatives\n",
    "#     mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, lifter=0, n_fft=2048, hop_length=512)\n",
    "#     mfcc_delta = librosa.feature.delta(mfcc)\n",
    "#     mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    \n",
    "#     # Concatenate the features and their derivatives into a single array\n",
    "#     features_row = np.concatenate((mfcc, mfcc_delta, mfcc_delta2))\n",
    "    \n",
    "#     # Add the filename as the final column\n",
    "#     file_name = file_path.split('/')[-1]  # Extract the filename from the file path\n",
    "#     features_row = np.append(features_row, file_name)\n",
    "    \n",
    "#     # Add the row of features to the list of features\n",
    "#     features.append(features_row)\n",
    "\n",
    "# # Convert the list of features to a DataFrame and save as a .csv file\n",
    "# df = pd.DataFrame(features)\n",
    "# df.to_csv('output.csv', header=False, index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function which extracts a feature vector from an audio file\n",
    "\n",
    "The feature extraction will calculate the first 13 mel-frequency cepstral coefficients of the audio file, as well as their first- and second-order derivatives, and concatenate them into a single 39-element feature vector. The feature vector is also standardized so that each feature has equal variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(y, sr):\n",
    "    y = y[0:sr]  # analyze just first second\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "    log_S = librosa.amplitude_to_db(S, ref=np.max)\n",
    "    mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
    "    delta_mfcc = librosa.feature.delta(mfcc, mode='nearest')\n",
    "    delta2_mfcc = librosa.feature.delta(mfcc, order=2, mode='nearest')\n",
    "    feature_vector = np.concatenate((np.mean(mfcc,1), np.mean(delta_mfcc,1), np.mean(delta2_mfcc,1)))\n",
    "    feature_vector = (feature_vector-np.mean(feature_vector)) / np.std(feature_vector)\n",
    "    return feature_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will iterate through all the files, and get their feature vectors, placing them into a new list feature_vectors. We also make a new array sound_paths to index the feature vectors to the correct paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get 1 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_0-4.5.wav\n",
      "get 101 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_1404.0-1408.5.wav\n",
      "get 201 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_1809.0-1813.5.wav\n",
      "get 301 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_2214.0-2218.5.wav\n",
      "get 401 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_2623.5-2628.0.wav\n",
      "get 501 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_3028.5-3033.0.wav\n",
      "get 601 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_3433.5-3438.0.wav\n",
      "get 701 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_3838.5-3843.0.wav\n",
      "get 801 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_4239.0-4243.5.wav\n",
      "get 901 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_4644.0-4648.5.wav\n",
      "get 1001 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_5049.0-5053.5.wav\n",
      "get 1101 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_5454.0-5458.5.wav\n",
      "get 1201 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_5859.0-5863.5.wav\n",
      "get 1301 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_6268.5-6273.0.wav\n",
      "get 1401 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_6673.5-6678.0.wav\n",
      "get 1501 of 1598 = D:\\PhD-data\\Tarcutta-DryA-test-8-10\\20210427T080000+1000_REC_7078.5-7083.0.wav\n",
      "calculated 1598 feature vectors\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "feature_vectors = []\n",
    "sound_paths = []\n",
    "for i,f in enumerate(files):\n",
    "    if i % 100 == 0:\n",
    "        print(\"get %d of %d = %s\"%(i+1, len(files), f))\n",
    "    y, sr = librosa.load(f)\n",
    "    if len(y) < 2:\n",
    "        print(\"error loading %s\" % f)\n",
    "        continue\n",
    "    feat = get_features(y, sr)\n",
    "    feature_vectors.append(feat)\n",
    "    sound_paths.append(f)\n",
    "        \n",
    "print(\"calculated %d feature vectors\"%len(feature_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0     0.226270  0.443418  0.410626  0.419659  0.633722  0.676938  0.591520   \n",
      "1     0.145844  0.333392  0.293124  0.311883  0.564713  0.638574  0.584935   \n",
      "2     0.078568  0.219208  0.200249  0.283833  0.619126  0.756490  0.730613   \n",
      "3     0.097331  0.272791  0.224572  0.249445  0.537682  0.654836  0.647059   \n",
      "4     0.121620  0.329649  0.266253  0.249356  0.487869  0.565022  0.538355   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "3191  0.178869  0.393789  0.343259  0.338939  0.573193  0.653699  0.627506   \n",
      "3192  0.167015  0.369053  0.347749  0.393560  0.655942  0.735766  0.667932   \n",
      "3193  0.204415  0.440544  0.382297  0.358366  0.573310  0.650591  0.634886   \n",
      "3194  0.263003  0.487067  0.449587  0.427122  0.621909  0.648746  0.590171   \n",
      "3195  0.342840  0.536433  0.523159  0.550152  0.757032  0.808196  0.735544   \n",
      "\n",
      "            7         8         9   ...        29        30        31  \\\n",
      "0     0.634224  0.568640  0.599689  ...  0.337106  0.333602  0.337379   \n",
      "1     0.657984  0.614488  0.679551  ...  0.428833  0.423543  0.424159   \n",
      "2     0.741713  0.631827  0.628702  ...  0.548497  0.541094  0.538519   \n",
      "3     0.722124  0.657084  0.692127  ...  0.518496  0.513173  0.517212   \n",
      "4     0.653706  0.626105  0.686175  ...  0.539056  0.533323  0.536011   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "3191  0.708490  0.652411  0.689784  ...  0.379907  0.376450  0.380850   \n",
      "3192  0.679682  0.576686  0.560278  ...  0.488638  0.479983  0.478111   \n",
      "3193  0.721304  0.655722  0.665097  ...  0.395598  0.394196  0.401111   \n",
      "3194  0.658059  0.621408  0.661571  ...  0.263891  0.267000  0.263603   \n",
      "3195  0.736268  0.625251  0.603834  ...  0.141405  0.137918  0.140113   \n",
      "\n",
      "            32        33        34        35        36        37        38  \n",
      "0     0.341173  0.343177  0.340617  0.333935  0.322418  0.320999  0.324923  \n",
      "1     0.426071  0.428981  0.430239  0.428713  0.422329  0.423190  0.427371  \n",
      "2     0.538415  0.540933  0.542783  0.541252  0.533824  0.531089  0.531818  \n",
      "3     0.522288  0.523899  0.519348  0.510936  0.500518  0.500013  0.505134  \n",
      "4     0.540603  0.543387  0.540825  0.533646  0.523115  0.521343  0.525314  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "3191  0.383567  0.382644  0.378342  0.373843  0.368077  0.371789  0.377539  \n",
      "3192  0.479524  0.483587  0.486534  0.485970  0.479695  0.479444  0.482985  \n",
      "3193  0.405791  0.405627  0.401507  0.397788  0.393944  0.399352  0.405246  \n",
      "3194  0.270966  0.266710  0.272376  0.264847  0.262139  0.256855  0.264069  \n",
      "3195  0.143107  0.148640  0.153017  0.152741  0.142753  0.140703  0.142551  \n",
      "\n",
      "[3196 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "x = feature_vectors\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "feature_vectors = pd.DataFrame(x_scaled)\n",
    "print(feature_vectors)\n",
    "df = pd.DataFrame(feature_vectors)\n",
    "paths = pd.DataFrame(sound_paths)\n",
    "df = pd.concat([df, paths], ignore_index=True, sort=False, axis=1)\n",
    "df.to_csv('39-features-Tarcutta-DryA-20210427T080000-20210427T100000-denoised.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run t-SNE over the feature vectors to get a 2-dimensional embedding of our audio files. We use scikit-learn's TSNE function, and additionally normalize the results so that they are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_vectors = pd.read_csv(\"39-features-tarcutta-sound.csv\")\n",
    "feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Drop rows containing missing values\n",
    "feature_vectors = feature_vectors.dropna()\n",
    "#feature_vectors.to_csv('39-features-esc50-cleaned.csv', index=False)\n",
    "feature_vectors = feature_vectors.drop(columns=[\"class\"])\n",
    "feature_vectors = feature_vectors.drop(columns=[\"path\"])\n",
    "feature_vectors = feature_vectors.iloc[:, 0:13]\n",
    "feature_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2, learning_rate=150, perplexity=50, verbose=2, angle=0.1).fit_transform(feature_vectors)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our t-SNE points. We can use matplotlib to quickly scatter them and see their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis=model[:,0]\n",
    "y_axis=model[:,1]\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.scatter(x_axis, y_axis)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see our t-SNE plot of our audio files, but it's not particularly interesting! Since we are dealing with audio files, there's no easy way to compare neighboring audio samples to each other. We can use some other, more interactive environment to view the results of the t-SNE. One way we can do this is by saving the results to a JSON file which stores the filepaths and t-SNE assignments of all the audio files. We can then load this JSON file in another environment.\n",
    "\n",
    "In any case, to save the t-SNE to a JSON file, we first normalize the coordinates to between 0 and 1 and save them, along with the full filepaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioProcessing import utils\n",
    "\n",
    "\n",
    "tsne_path = \"example-audio-tSNE.json\"\n",
    "\n",
    "x_norm = (x_axis - np.min(x_axis)) / (np.max(x_axis) - np.min(x_axis))\n",
    "y_norm = (y_axis - np.min(y_axis)) / (np.max(y_axis) - np.min(y_axis))\n",
    "\n",
    "data = [{\"path\":os.path.abspath(f), \"point\":[x, y]} for f, x, y in zip(sound_paths, x_norm, y_norm)]\n",
    "# with open(tsne_path, 'w') as outfile:\n",
    "utils.write_to_json(tsne_path, str(data))\n",
    "    # json.dump(data, outfile, cls=)\n",
    "\n",
    "print(\"saved %s to disk!\" % tsne_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=4, init='k-means++', random_state=42)\n",
    "y_km = km.fit_predict(model)\n",
    "labels = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[y_km == 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 3 clusters\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.scatter(\n",
    "    model[y_km == 0, 0], model[y_km == 0, 1],\n",
    "    s=50, c='lightgreen',\n",
    "    marker='s', edgecolor='black',\n",
    "    label='cluster 1'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    model[y_km == 1, 0], model[y_km == 1, 1],\n",
    "    s=50, c='orange',\n",
    "    marker='o', edgecolor='black',\n",
    "    label='cluster 2'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    model[y_km == 2, 0], model[y_km == 2, 1],\n",
    "    s=50, c='lightblue',\n",
    "    marker='v', edgecolor='black',\n",
    "    label='cluster 3'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    model[y_km == 3, 0], model[y_km == 3, 1],\n",
    "    s=50, c='blue',\n",
    "    marker='v', edgecolor='black',\n",
    "    label='cluster 3'\n",
    ")\n",
    "\n",
    "# plot the centroids\n",
    "plt.scatter(\n",
    "    km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n",
    "    s=250, marker='*',\n",
    "    c='red', edgecolor='black',\n",
    "    label='centroids'\n",
    ")\n",
    "plt.legend(scatterpoints=1)\n",
    "plt.title('Clusters by t-SNE Components (with Dimension Reduction)', fontsize=20)\n",
    "plt.xlabel(\"Component 2\", fontsize=18)\n",
    "plt.ylabel(\"Component 1\", fontsize=18)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_data_old = pd.read_csv('kmeans_results.csv')\n",
    "\n",
    "#encoding class values\n",
    "kmeans_data_old['class'] = kmeans_data_old['class'].str.replace('other', str(0))\n",
    "kmeans_data_old['class'] = kmeans_data_old['class'].str.replace('biophony', str(1))\n",
    "kmeans_data_old['class'] = kmeans_data_old['class'].str.replace('geophony', str(2))\n",
    "kmeans_data_old['class'] = kmeans_data_old['class'].str.replace('anthrophony', str(3))\n",
    "\n",
    "y_km = kmeans_data_old['class']\n",
    "y_km.drop(y_km.tail(1).index, inplace=True)\n",
    "y_km = y_km.values\n",
    "y_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "x_axis=model[:,0]\n",
    "y_axis=model[:,1]\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(\n",
    "    x=x_axis, y=y_axis,\n",
    "    hue=y_km,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3,\n",
    "    palette=['green','orange','dodgerblue','red']\n",
    ")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, ['Anthrophony', 'Biophony', 'Geophony', 'Other'])\n",
    "ax.set(title=\"TSNE Plot with Ground Truth Overlayed\", ylabel=\"TSNE Component 1\", xlabel=\"TSNE Component 2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: GET STATISTICS FOR ALL OF THE ABOVE GRAPHS\n",
    "TODO: CREATE ADDITIONAL GRAPH (USING SAME TSNE RESULTS) WITHOUT DIMENSION REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_data_new = pd.read_csv('kmeans-nodr.csv', header='infer')\n",
    "kmeans_data_new.drop(kmeans_data_new.tail(1).index,inplace=True) # drop last n rows\n",
    "\n",
    "y_km = kmeans_data_new[\"Cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "x_axis=model[:,0]\n",
    "y_axis=model[:,1]\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(\n",
    "    x=x_axis, y=y_axis,\n",
    "    hue=y_km,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3,\n",
    "    palette=['green','orange','dodgerblue','red']\n",
    ")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, ['Geophony', 'Anthrophony', 'Biophony', 'Other'])\n",
    "ax.set(title=\"Kmeans Clustering Results without Dimension Reduction\", ylabel=\"TSNE Component 1\", xlabel=\"TSNE Component 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_data_old = pd.read_csv('kmeans_results.csv', header='infer')\n",
    "\n",
    "kmeans_data_old.drop(kmeans_data_old.tail(1).index,inplace=True) # drop last n rows\n",
    "y_km = kmeans_data_old[\"kmeans_class\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "x_axis=model[:,0]\n",
    "y_axis=model[:,1]\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(\n",
    "    x=x_axis, y=y_axis,\n",
    "    hue=y_km,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3,\n",
    "    palette=['green','orange','dodgerblue','red']\n",
    ")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, ['Anthrophony', 'Other', 'Biophony', 'Geophony'])\n",
    "ax.set(title=\"Kmeans Clustering Results with Dimension Reduction\", ylabel=\"TSNE Component 1\", xlabel=\"TSNE Component 2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will however be able to calculate statistics like within group variance and between group variance. The goal is to have low within group variance and high between group variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: append results to k-means and use metrics to evaluate results against ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kmeans.csv')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_df = pd.DataFrame(labels, columns=[\"kmeans_class\"])\n",
    "\n",
    "df = pd.concat([df, kmeans_df], axis=1)\n",
    "print(df)\n",
    "df.to_csv(\"kmeans_results.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rand Index - similarity of the two clustering assignments\n",
    "Biophony = 0\n",
    "Other = 1\n",
    "Anthrophony = 2\n",
    "Geophony = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans_df['kmeans_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "kmeans_data = pd.read_csv('kmeans_results.csv', header='infer')\n",
    "\n",
    "labels_pred = kmeans_data['kmeans_class']\n",
    "\n",
    "\n",
    "#encoding class values\n",
    "kmeans_data['class'] = kmeans_data['class'].str.replace('other', str(1))\n",
    "kmeans_data['class'] = kmeans_data['class'].str.replace('biophony', str(0))\n",
    "kmeans_data['class'] = kmeans_data['class'].str.replace('geophony', str(3))\n",
    "kmeans_data['class'] = kmeans_data['class'].str.replace('anthrophony', str(2))\n",
    "\n",
    "#print(kmeans_data)\n",
    "\n",
    "labels_true = kmeans_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.rand_score(labels_true, labels_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rand index does not ensure to obtain a value close to 0.0 for a random labelling. The adjusted Rand index corrects for chance and will give such a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.adjusted_rand_score(labels_true, labels_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutual Information is a function that measures the agreement of the two assignments, ignoring permutations. Two different normalized versions of this measure are available, Normalized Mutual Information (NMI) and Adjusted Mutual Information (AMI). NMI is often used in the literature, while AMI was proposed more recently and is normalized against chance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.adjusted_mutual_info_score(labels_true, labels_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "homogeneity: each cluster contains only members of a single class.\n",
    "\n",
    "completeness: all members of a given class are assigned to the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.homogeneity_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.completeness_score(labels_true, labels_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their harmonic mean called V-measure is computed by v_measure_score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.v_measure_score(labels_true, labels_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fowlkes-Mallows score FMI is defined as the geometric mean of the pairwise precision and recall. A high value indicates a good similarity between two clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.fowlkes_mallows_score(labels_true, labels_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f82b60afc9e769353ca8e23ca0788a91521f3b1d90a0d850df22b067a5f0348b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
