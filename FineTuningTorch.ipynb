{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.12.0+cpu\n",
      "Torchvision Version:  0.13.0+cpu\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1duvcvhk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▂▄▅▅▆▆▇▆▆▆▇▇▇▇▇▇▇███▁▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅</td></tr><tr><td>train_loss</td><td>▇▆▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁█▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄</td></tr><tr><td>val_accuracy</td><td>▅▅▄▆▆▅▆▄▅▄▄▆▆▆▆▆█▅▇▇▁▁▃▄▅▂▄▂▃▃▂▂▄▃▄▂▃▄▄▆</td></tr><tr><td>val_loss</td><td>▄▅▆▅▃▄▂▆▃▆▅▃▄▂▄▃▁▃▂▃▄▄▅▅▅▆▅▅▅▅▇█▄▇▅▇▅▅▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.64855</td></tr><tr><td>train_loss</td><td>0.8725</td></tr><tr><td>val_accuracy</td><td>0.5598</td></tr><tr><td>val_loss</td><td>1.94639</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-leaf-5</strong>: <a href=\"https://wandb.ai/tnapier/a2o-initial-test/runs/1duvcvhk\" target=\"_blank\">https://wandb.ai/tnapier/a2o-initial-test/runs/1duvcvhk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220727_011906-1duvcvhk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1duvcvhk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Thomas\\AudioHandling\\wandb\\run-20220728_010919-2qfhh4sf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tnapier/a2o-initial-test/runs/2qfhh4sf\" target=\"_blank\">blooming-glade-6</a></strong> to <a href=\"https://wandb.ai/tnapier/a2o-initial-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"a2o-initial-test\", entity=\"tnapier\")\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 50,\n",
    "  \"batch_size\": 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms \n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"D:\\\\PhD\\data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"inception\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 4\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 50\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            if phase == 'train':\n",
    "                wandb.log({\"train_loss\": epoch_loss})\n",
    "                wandb.log({\"train_accuracy\": epoch_acc})            \n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                wandb.log({\"val_loss\": epoch_loss})\n",
    "                wandb.log({\"val_accuracy\": epoch_acc})       \n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thomas\\conda\\envs\\audiohandling\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=4, bias=True)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t Conv2d_1a_3x3.conv.weight\n",
      "\t Conv2d_1a_3x3.bn.weight\n",
      "\t Conv2d_1a_3x3.bn.bias\n",
      "\t Conv2d_2a_3x3.conv.weight\n",
      "\t Conv2d_2a_3x3.bn.weight\n",
      "\t Conv2d_2a_3x3.bn.bias\n",
      "\t Conv2d_2b_3x3.conv.weight\n",
      "\t Conv2d_2b_3x3.bn.weight\n",
      "\t Conv2d_2b_3x3.bn.bias\n",
      "\t Conv2d_3b_1x1.conv.weight\n",
      "\t Conv2d_3b_1x1.bn.weight\n",
      "\t Conv2d_3b_1x1.bn.bias\n",
      "\t Conv2d_4a_3x3.conv.weight\n",
      "\t Conv2d_4a_3x3.bn.weight\n",
      "\t Conv2d_4a_3x3.bn.bias\n",
      "\t Mixed_5b.branch1x1.conv.weight\n",
      "\t Mixed_5b.branch1x1.bn.weight\n",
      "\t Mixed_5b.branch1x1.bn.bias\n",
      "\t Mixed_5b.branch5x5_1.conv.weight\n",
      "\t Mixed_5b.branch5x5_1.bn.weight\n",
      "\t Mixed_5b.branch5x5_1.bn.bias\n",
      "\t Mixed_5b.branch5x5_2.conv.weight\n",
      "\t Mixed_5b.branch5x5_2.bn.weight\n",
      "\t Mixed_5b.branch5x5_2.bn.bias\n",
      "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_5b.branch_pool.conv.weight\n",
      "\t Mixed_5b.branch_pool.bn.weight\n",
      "\t Mixed_5b.branch_pool.bn.bias\n",
      "\t Mixed_5c.branch1x1.conv.weight\n",
      "\t Mixed_5c.branch1x1.bn.weight\n",
      "\t Mixed_5c.branch1x1.bn.bias\n",
      "\t Mixed_5c.branch5x5_1.conv.weight\n",
      "\t Mixed_5c.branch5x5_1.bn.weight\n",
      "\t Mixed_5c.branch5x5_1.bn.bias\n",
      "\t Mixed_5c.branch5x5_2.conv.weight\n",
      "\t Mixed_5c.branch5x5_2.bn.weight\n",
      "\t Mixed_5c.branch5x5_2.bn.bias\n",
      "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_5c.branch_pool.conv.weight\n",
      "\t Mixed_5c.branch_pool.bn.weight\n",
      "\t Mixed_5c.branch_pool.bn.bias\n",
      "\t Mixed_5d.branch1x1.conv.weight\n",
      "\t Mixed_5d.branch1x1.bn.weight\n",
      "\t Mixed_5d.branch1x1.bn.bias\n",
      "\t Mixed_5d.branch5x5_1.conv.weight\n",
      "\t Mixed_5d.branch5x5_1.bn.weight\n",
      "\t Mixed_5d.branch5x5_1.bn.bias\n",
      "\t Mixed_5d.branch5x5_2.conv.weight\n",
      "\t Mixed_5d.branch5x5_2.bn.weight\n",
      "\t Mixed_5d.branch5x5_2.bn.bias\n",
      "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_5d.branch_pool.conv.weight\n",
      "\t Mixed_5d.branch_pool.bn.weight\n",
      "\t Mixed_5d.branch_pool.bn.bias\n",
      "\t Mixed_6a.branch3x3.conv.weight\n",
      "\t Mixed_6a.branch3x3.bn.weight\n",
      "\t Mixed_6a.branch3x3.bn.bias\n",
      "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_6b.branch1x1.conv.weight\n",
      "\t Mixed_6b.branch1x1.bn.weight\n",
      "\t Mixed_6b.branch1x1.bn.bias\n",
      "\t Mixed_6b.branch7x7_1.conv.weight\n",
      "\t Mixed_6b.branch7x7_1.bn.weight\n",
      "\t Mixed_6b.branch7x7_1.bn.bias\n",
      "\t Mixed_6b.branch7x7_2.conv.weight\n",
      "\t Mixed_6b.branch7x7_2.bn.weight\n",
      "\t Mixed_6b.branch7x7_2.bn.bias\n",
      "\t Mixed_6b.branch7x7_3.conv.weight\n",
      "\t Mixed_6b.branch7x7_3.bn.weight\n",
      "\t Mixed_6b.branch7x7_3.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6b.branch_pool.conv.weight\n",
      "\t Mixed_6b.branch_pool.bn.weight\n",
      "\t Mixed_6b.branch_pool.bn.bias\n",
      "\t Mixed_6c.branch1x1.conv.weight\n",
      "\t Mixed_6c.branch1x1.bn.weight\n",
      "\t Mixed_6c.branch1x1.bn.bias\n",
      "\t Mixed_6c.branch7x7_1.conv.weight\n",
      "\t Mixed_6c.branch7x7_1.bn.weight\n",
      "\t Mixed_6c.branch7x7_1.bn.bias\n",
      "\t Mixed_6c.branch7x7_2.conv.weight\n",
      "\t Mixed_6c.branch7x7_2.bn.weight\n",
      "\t Mixed_6c.branch7x7_2.bn.bias\n",
      "\t Mixed_6c.branch7x7_3.conv.weight\n",
      "\t Mixed_6c.branch7x7_3.bn.weight\n",
      "\t Mixed_6c.branch7x7_3.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6c.branch_pool.conv.weight\n",
      "\t Mixed_6c.branch_pool.bn.weight\n",
      "\t Mixed_6c.branch_pool.bn.bias\n",
      "\t Mixed_6d.branch1x1.conv.weight\n",
      "\t Mixed_6d.branch1x1.bn.weight\n",
      "\t Mixed_6d.branch1x1.bn.bias\n",
      "\t Mixed_6d.branch7x7_1.conv.weight\n",
      "\t Mixed_6d.branch7x7_1.bn.weight\n",
      "\t Mixed_6d.branch7x7_1.bn.bias\n",
      "\t Mixed_6d.branch7x7_2.conv.weight\n",
      "\t Mixed_6d.branch7x7_2.bn.weight\n",
      "\t Mixed_6d.branch7x7_2.bn.bias\n",
      "\t Mixed_6d.branch7x7_3.conv.weight\n",
      "\t Mixed_6d.branch7x7_3.bn.weight\n",
      "\t Mixed_6d.branch7x7_3.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6d.branch_pool.conv.weight\n",
      "\t Mixed_6d.branch_pool.bn.weight\n",
      "\t Mixed_6d.branch_pool.bn.bias\n",
      "\t Mixed_6e.branch1x1.conv.weight\n",
      "\t Mixed_6e.branch1x1.bn.weight\n",
      "\t Mixed_6e.branch1x1.bn.bias\n",
      "\t Mixed_6e.branch7x7_1.conv.weight\n",
      "\t Mixed_6e.branch7x7_1.bn.weight\n",
      "\t Mixed_6e.branch7x7_1.bn.bias\n",
      "\t Mixed_6e.branch7x7_2.conv.weight\n",
      "\t Mixed_6e.branch7x7_2.bn.weight\n",
      "\t Mixed_6e.branch7x7_2.bn.bias\n",
      "\t Mixed_6e.branch7x7_3.conv.weight\n",
      "\t Mixed_6e.branch7x7_3.bn.weight\n",
      "\t Mixed_6e.branch7x7_3.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6e.branch_pool.conv.weight\n",
      "\t Mixed_6e.branch_pool.bn.weight\n",
      "\t Mixed_6e.branch_pool.bn.bias\n",
      "\t AuxLogits.conv0.conv.weight\n",
      "\t AuxLogits.conv0.bn.weight\n",
      "\t AuxLogits.conv0.bn.bias\n",
      "\t AuxLogits.conv1.conv.weight\n",
      "\t AuxLogits.conv1.bn.weight\n",
      "\t AuxLogits.conv1.bn.bias\n",
      "\t AuxLogits.fc.weight\n",
      "\t AuxLogits.fc.bias\n",
      "\t Mixed_7a.branch3x3_1.conv.weight\n",
      "\t Mixed_7a.branch3x3_1.bn.weight\n",
      "\t Mixed_7a.branch3x3_1.bn.bias\n",
      "\t Mixed_7a.branch3x3_2.conv.weight\n",
      "\t Mixed_7a.branch3x3_2.bn.weight\n",
      "\t Mixed_7a.branch3x3_2.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
      "\t Mixed_7b.branch1x1.conv.weight\n",
      "\t Mixed_7b.branch1x1.bn.weight\n",
      "\t Mixed_7b.branch1x1.bn.bias\n",
      "\t Mixed_7b.branch3x3_1.conv.weight\n",
      "\t Mixed_7b.branch3x3_1.bn.weight\n",
      "\t Mixed_7b.branch3x3_1.bn.bias\n",
      "\t Mixed_7b.branch3x3_2a.conv.weight\n",
      "\t Mixed_7b.branch3x3_2a.bn.weight\n",
      "\t Mixed_7b.branch3x3_2a.bn.bias\n",
      "\t Mixed_7b.branch3x3_2b.conv.weight\n",
      "\t Mixed_7b.branch3x3_2b.bn.weight\n",
      "\t Mixed_7b.branch3x3_2b.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
      "\t Mixed_7b.branch_pool.conv.weight\n",
      "\t Mixed_7b.branch_pool.bn.weight\n",
      "\t Mixed_7b.branch_pool.bn.bias\n",
      "\t Mixed_7c.branch1x1.conv.weight\n",
      "\t Mixed_7c.branch1x1.bn.weight\n",
      "\t Mixed_7c.branch1x1.bn.bias\n",
      "\t Mixed_7c.branch3x3_1.conv.weight\n",
      "\t Mixed_7c.branch3x3_1.bn.weight\n",
      "\t Mixed_7c.branch3x3_1.bn.bias\n",
      "\t Mixed_7c.branch3x3_2a.conv.weight\n",
      "\t Mixed_7c.branch3x3_2a.bn.weight\n",
      "\t Mixed_7c.branch3x3_2a.bn.bias\n",
      "\t Mixed_7c.branch3x3_2b.conv.weight\n",
      "\t Mixed_7c.branch3x3_2b.bn.weight\n",
      "\t Mixed_7c.branch3x3_2b.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
      "\t Mixed_7c.branch_pool.conv.weight\n",
      "\t Mixed_7c.branch_pool.bn.weight\n",
      "\t Mixed_7c.branch_pool.bn.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.7361 Acc: 0.4509\n",
      "val Loss: 1.1404 Acc: 0.6561\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.5367 Acc: 0.5251\n",
      "val Loss: 1.3576 Acc: 0.6346\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.4683 Acc: 0.5661\n",
      "val Loss: 1.2161 Acc: 0.6262\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.3960 Acc: 0.6062\n",
      "val Loss: 1.5459 Acc: 0.5930\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.3426 Acc: 0.6163\n",
      "val Loss: 1.3331 Acc: 0.6096\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.2706 Acc: 0.6205\n",
      "val Loss: 1.5379 Acc: 0.5399\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.2712 Acc: 0.6260\n",
      "val Loss: 1.2952 Acc: 0.5797\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.2377 Acc: 0.6536\n",
      "val Loss: 1.5029 Acc: 0.5332\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.1632 Acc: 0.6702\n",
      "val Loss: 1.2955 Acc: 0.5814\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.1605 Acc: 0.6702\n",
      "val Loss: 0.9697 Acc: 0.6578\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.1065 Acc: 0.6914\n",
      "val Loss: 1.4588 Acc: 0.5930\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.0778 Acc: 0.6895\n",
      "val Loss: 1.4195 Acc: 0.6346\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.1089 Acc: 0.6734\n",
      "val Loss: 2.1569 Acc: 0.5282\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.0385 Acc: 0.7140\n",
      "val Loss: 1.3011 Acc: 0.5249\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.0799 Acc: 0.7052\n",
      "val Loss: 1.4749 Acc: 0.6113\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.9842 Acc: 0.7269\n",
      "val Loss: 0.8769 Acc: 0.6346\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.0089 Acc: 0.7227\n",
      "val Loss: 2.0368 Acc: 0.3937\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.9514 Acc: 0.7338\n",
      "val Loss: 1.2916 Acc: 0.5449\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.9874 Acc: 0.7374\n",
      "val Loss: 1.0133 Acc: 0.6130\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.9322 Acc: 0.7361\n",
      "val Loss: 2.0956 Acc: 0.4934\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.9363 Acc: 0.7328\n",
      "val Loss: 1.4301 Acc: 0.5316\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.9124 Acc: 0.7531\n",
      "val Loss: 1.8128 Acc: 0.5615\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.9436 Acc: 0.7503\n",
      "val Loss: 1.8028 Acc: 0.6096\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.8765 Acc: 0.7568\n",
      "val Loss: 2.7962 Acc: 0.5748\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.8411 Acc: 0.7706\n",
      "val Loss: 3.0355 Acc: 0.3854\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.8306 Acc: 0.7706\n",
      "val Loss: 1.7415 Acc: 0.5465\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.8478 Acc: 0.7757\n",
      "val Loss: 1.6311 Acc: 0.5615\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.8609 Acc: 0.7669\n",
      "val Loss: 1.2966 Acc: 0.5880\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.8332 Acc: 0.7669\n",
      "val Loss: 1.4904 Acc: 0.5731\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.8116 Acc: 0.7867\n",
      "val Loss: 2.8649 Acc: 0.5897\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.7810 Acc: 0.7964\n",
      "val Loss: 1.9485 Acc: 0.5133\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.7710 Acc: 0.7959\n",
      "val Loss: 1.7738 Acc: 0.5282\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.7512 Acc: 0.8001\n",
      "val Loss: 3.2255 Acc: 0.5266\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.7864 Acc: 0.7886\n",
      "val Loss: 2.4839 Acc: 0.5150\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.7473 Acc: 0.8056\n",
      "val Loss: 2.1010 Acc: 0.5515\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.7014 Acc: 0.8176\n",
      "val Loss: 2.6979 Acc: 0.4369\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.7336 Acc: 0.7996\n",
      "val Loss: 1.7575 Acc: 0.6030\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.7040 Acc: 0.8024\n",
      "val Loss: 2.5515 Acc: 0.4900\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.6921 Acc: 0.8194\n",
      "val Loss: 2.3828 Acc: 0.5349\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.7013 Acc: 0.8033\n",
      "val Loss: 2.3600 Acc: 0.5183\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.6862 Acc: 0.8199\n",
      "val Loss: 0.9145 Acc: 0.7076\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.6725 Acc: 0.8217\n",
      "val Loss: 1.8730 Acc: 0.5615\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.6688 Acc: 0.8199\n",
      "val Loss: 1.7330 Acc: 0.5963\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.6252 Acc: 0.8356\n",
      "val Loss: 1.3351 Acc: 0.6678\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.6322 Acc: 0.8333\n",
      "val Loss: 1.0500 Acc: 0.6877\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.6697 Acc: 0.8185\n",
      "val Loss: 1.2434 Acc: 0.5548\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.6108 Acc: 0.8434\n",
      "val Loss: 1.4549 Acc: 0.5150\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.6358 Acc: 0.8273\n",
      "val Loss: 2.7261 Acc: 0.4169\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.6277 Acc: 0.8360\n",
      "val Loss: 1.8635 Acc: 0.5482\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.5830 Acc: 0.8489\n",
      "val Loss: 1.9045 Acc: 0.5000\n",
      "\n",
      "Training complete in 605m 15s\n",
      "Best val Acc: 0.707641\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thomas\\conda\\envs\\audiohandling\\lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.9307 Acc: 0.3538\n",
      "val Loss: 1.4050 Acc: 0.3322\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.9531 Acc: 0.3634\n",
      "val Loss: 1.6548 Acc: 0.2625\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.9199 Acc: 0.3653\n",
      "val Loss: 1.5788 Acc: 0.0831\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.9067 Acc: 0.3676\n",
      "val Loss: 1.3336 Acc: 0.2425\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.8882 Acc: 0.3819\n",
      "val Loss: 1.3109 Acc: 0.1860\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.8985 Acc: 0.3800\n",
      "val Loss: 1.3572 Acc: 0.2575\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.9541 Acc: 0.3731\n",
      "val Loss: 1.3992 Acc: 0.1860\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.9380 Acc: 0.3625\n",
      "val Loss: 1.6097 Acc: 0.2841\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.8910 Acc: 0.3819\n",
      "val Loss: 1.5809 Acc: 0.1362\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.9172 Acc: 0.3819\n",
      "val Loss: 1.4099 Acc: 0.1478\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.9021 Acc: 0.3782\n",
      "val Loss: 1.4629 Acc: 0.1495\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.8982 Acc: 0.4017\n",
      "val Loss: 1.5012 Acc: 0.4136\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.9329 Acc: 0.3842\n",
      "val Loss: 1.4324 Acc: 0.1063\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.8581 Acc: 0.4123\n",
      "val Loss: 1.4730 Acc: 0.1512\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.8507 Acc: 0.4113\n",
      "val Loss: 1.7202 Acc: 0.1279\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.8464 Acc: 0.4182\n",
      "val Loss: 1.4319 Acc: 0.2625\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.8363 Acc: 0.4164\n",
      "val Loss: 1.9640 Acc: 0.0947\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 1.8658 Acc: 0.4007\n",
      "val Loss: 1.4622 Acc: 0.1794\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 1.8368 Acc: 0.4159\n",
      "val Loss: 1.6598 Acc: 0.4618\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.8453 Acc: 0.4150\n",
      "val Loss: 2.2242 Acc: 0.2857\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Initialize the non-pretrained version of the model used for this run\n",
    "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "\n",
    "# Plot the training curves of validation accuracy vs. number \n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/finetuning_torchvision_models_tutorial.ipynb#scrollTo=wYQEfMSWdCWP"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cb7461182531ee4d1fecde1160009f8d4e82a4e5b71e588d6526f0d447710c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('audiohandling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
